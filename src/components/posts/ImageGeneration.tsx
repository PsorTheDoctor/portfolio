import { Wrapper, Title, Subtitle, Image, Img } from "./Style";
import Kangaroo from "../../images/kangaroo.jpg";
import Adam from "../../images/fgsm.jpg";

type PropsType = {};

export const ImageGeneration = (props: PropsType) => (
  <Wrapper>
    <Title>Testing image generation tools</Title>
    <Subtitle>Overview of DALL-E text-to-image generator OpenAI kindly shared with me.</Subtitle>

    <p>DALL-E 2 is AI system that can create realistic images from description
    in natural language, image edits and variations. It's successor of DALL-E presented
    just a year before exceeding its possibilities. The best thing of this model is it can
    produce coherent illustrations by joining various concepts, attributes and styles of different level 
    of abstraction, such as kangaroo wearing an orange hoodie and blue sunglasses etc.</p>

    <Image>
      <Img src={Kangaroo} width="600px" alt="Kangaroo wearing an orange hoodie and blue sunglasses" />
      <p>Kangaroo wearing an orange hoodie and blue sunglasses in photorealistic style.</p>
    </Image>

    <p><b>The rise of generative art</b></p>
    <p>In this place it should to be said that creating art by AI isn't a fresh idea
    and this concept refers to a field called generative art. Simply, it means art
    generated by machines. So far, it was dominated by Generative Adversarial Networks
    (StackGAN could even allow to very limited text-to-image generation). These days
    they're usually replaced by diffusion models. 2022 was especially prolific year 
    for them giving us DALL-E 2 followed by Google's Imagen and Parti.</p>

    <p>To avoid explicit usage of the model generation of some topics including 
    realistic human faces has been prohibited. Anyway, I've managed to create the variations
    of mine fooling the censorship system by FGSM (Fast Gradient Signed Method) attack.
    The results were rather quite satisfying.</p>

    <Image>
      <Img src={Adam} width="600px" alt="Variations of my face" />
      <p>Variations of my face.</p>
    </Image>

    <p>Telling the truth, it's actually third product OpenAI has shared with me. 
    Before that I was testing GPT-3 and its fine-tuned Codex model (GitHub Copilot 
    is powered by it). Being a witness of how they could write natural language and code
    also was exciting experience (GPT-3 even did my homework once), but images are a completely
    different story. It allows to see how much deep understanding actually is producing
    truly creative and unusual samples.
    </p>
  </Wrapper>
);
